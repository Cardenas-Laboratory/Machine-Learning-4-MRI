function [metrics,CM,validationAccuracy] = trainLDA(predictors,response,folds,posClass)
% trainClassifier(trainingData)
%  returns a trained classifier and its accuracy.
%  This code recreates the classification model trained in
%  Classification Learner app.
%
%   Input:
%       trainingData: the training data of same data type as imported
%        in the app (table or matrix).
%
%   Output:
%       trainedClassifier: a struct containing the trained classifier.
%        The struct contains various fields with information about the
%        trained classifier.
%
%       trainedClassifier.predictFcn: a function to make predictions
%        on new data. It takes an input of the same form as this training
%        code (table or matrix) and returns predictions for the response.
%        If you supply a matrix, include only the predictors columns (or
%        rows).
%
%       validationAccuracy: a double containing the accuracy in
%        percent. In the app, the History list displays this
%        overall accuracy score for each model.
%
%  Use the code to train the model with new data.
%  To retrain your classifier, call the function from the command line
%  with your original data or new data as the input argument trainingData.
%
%  For example, to retrain a classifier trained with the original data set
%  T, enter:
%    [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
%  To make predictions with the returned 'trainedClassifier' on new data T,
%  use
%    yfit = trainedClassifier.predictFcn(T)
%
%  To automate training the same classifier with new data, or to learn how
%  to programmatically train classifiers, examine the generated code.

% Auto-generated by MATLAB on 15-Nov-2016 09:49:43


% Extract predictors and response
% This code processes the data into the right shape for training the
% classifier.
if ~istable(predictors)
    predictors=array2table(predictors);
end
predictorNames = predictors.Properties.VariableNames;
if istable(response) || iscell(response)
    if ischar(response{1})
        numresponse = zeros(length(response),1);
        str_store = cell(1,1);
        str_store{1}=response{1};
        count = 1;
        for j=1:length(response)
            check=1;
            num=0;
            for k=1:length(str_store)
                if ~strcmp(str_store{k},response{j})
                    check=check+1;
                else
                    num=k;
                end
            end
            if count~=check
                count=count+1;
                str_store{count}=response{j};
                num=count;
            end
            numresponse(j)=num-1;
        end
        response=numresponse;
    else
        if iscell(response)
            response=cell2mat(response);
        else
            response=table2array(response);
        end
        if min(response)~=0
            response=response-min(response);
            posClass=posClass-min(response);
        end
    end
end
isCategoricalPredictor = false(1,size(predictors,2));
if isstring(posClass) || ischar(posClass)
    for k=1:length(str_store)
        if strcmp(str_store{k},posClass)
            posClass=k;
        end
    end
else
    for j=1:length(response)
        if posClass==response(j)
            posClass=response(j)+1;
            break;
        end
    end
end
if isstring(posClass) || ischar(posClass) || isempty(find(response==(posClass-1), 1))
    posClass=1;
    disp('Could not find designated Positive Class. Reverting to default.');
end

% Train a classifier
% This code specifies all the classifier options and trains the classifier.
classificationDiscriminant = fitcdiscr(...
    predictors, ...
    response, ...
    'DiscrimType', 'diagLinear', ...
    'FillCoeffs', 'off', ...
    'SaveMemory', 'on', ...
    'ClassNames', (min(response):1:max(response))');

% Create the result struct with predict function
predictorExtractionFcn = @(t) t(:, predictorNames);
discriminantPredictFcn = @(x) predict(classificationDiscriminant, x);
trainedClassifier.predictFcn = @(x) discriminantPredictFcn(predictorExtractionFcn(x));

% Add additional fields to the result struct
trainedClassifier.RequiredVariables = predictorNames;
trainedClassifier.ClassificationDiscriminant = classificationDiscriminant;
trainedClassifier.About = 'This struct is a trained classifier exported from Classification Learner R2016b.';
trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedClassifier''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

% Perform cross-validation
partitionedModel = crossval(trainedClassifier.ClassificationDiscriminant, 'KFold', folds);

% Compute validation accuracy
validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');

% Compute validation predictions and scores
[validationPredictions, validationScores] = kfoldPredict(partitionedModel);

[metrics,CM]=ClassificationPerformance(response,validationPredictions,validationScores(:,posClass),posClass);
end

function [Metrics,ConfusionMatrix]=ClassificationPerformance(TrueLabels,PredictedLabels,Scores,posClass)
 
%   AUC
[~,~,~,AUC]= perfcurve(TrueLabels,Scores,posClass-1);


%   Kappa
ConfusionMatrix=confusionmat(TrueLabels,PredictedLabels);
Kappa=kappaJCR(   ConfusionMatrix);

%   accuracy
accuracy=sum(diag(ConfusionMatrix)) / sum(ConfusionMatrix(:));

% Allocate Output
Metrics=[AUC,accuracy,Kappa];
end
